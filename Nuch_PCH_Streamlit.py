import streamlit as st
import pandas as pd
import io
import requests
import urllib.parse
import plotly.express as px

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---
URL_STRUCT = "https://raw.githubusercontent.com/denmalysheff/Nuch/refs/heads/main/adm_struktur.xlsx"

st.set_page_config(page_title="–ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –ü–ß-22", layout="wide")

@st.cache_data
def load_admin_structure(url):
    try:
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ —Å—Å—ã–ª–∫–∏ GitHub Raw
        url = url.replace("Nuch/raw/refs", "Nuch/refs")
        parsed_url = list(urllib.parse.urlparse(url))
        parsed_url[2] = urllib.parse.quote(parsed_url[2])
        encoded_url = urllib.parse.urlunparse(parsed_url)
        
        response = requests.get(encoded_url, timeout=15)
        response.raise_for_status() 
        
        df = pd.read_excel(io.BytesIO(response.content), engine='openpyxl')
        df.columns = [col.strip().upper() for col in df.columns]
        
        if '–ö–ú–ö–û–ù' in df.columns and '–ö–ú–ù–ê–ß' in df.columns:
            df['–ü–õ–ê–ù_–î–õ–ò–ù–ê'] = abs(df['–ö–ú–ö–û–ù'] - df['–ö–ú–ù–ê–ß'])
        return df
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞ GitHub: {e}")
        return None

def calculate_metrics(group_name, group_data, level, plan_km=0):
    """–ï–¥–∏–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ä–∞—Å—á–µ—Ç–∞ N—É—á –∏ –ø–æ–ª–Ω–æ—Ç—ã"""
    fact_km = group_data["–ü–†–û–í–ï–†–ï–ù–û"].sum()
    
    # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –æ—Ü–µ–Ω–∫–∞–º
    km_5 = group_data[group_data["–û–¶–ï–ù–ö–ê"] == 5]["–ü–†–û–í–ï–†–ï–ù–û"].sum()
    km_4 = group_data[group_data["–û–¶–ï–ù–ö–ê"] == 4]["–ü–†–û–í–ï–†–ï–ù–û"].sum()
    km_3 = group_data[group_data["–û–¶–ï–ù–ö–ê"] == 3]["–ü–†–û–í–ï–†–ï–ù–û"].sum()
    km_2 = group_data[group_data["–û–¶–ï–ù–ö–ê"] == 2]["–ü–†–û–í–ï–†–ï–ù–û"].sum()

    n_uch = 0
    if fact_km > 0:
        n_uch = (km_5*5 + km_4*4 + km_3*3 - km_2*5) / fact_km

    return {
        "–£—Ä–æ–≤–µ–Ω—å": level,
        "–ì—Ä—É–ø–ø–∞": group_name,
        "N—É—á": round(n_uch, 2),
        "–ü—Ä–æ–≤–µ—Ä–µ–Ω–æ (–∫–º)": round(fact_km, 3),
        "–ü–ª–∞–Ω (–∫–º)": round(plan_km, 3),
        "–ü–æ–ª–Ω–æ—Ç–∞ %": round((fact_km / plan_km * 100), 1) if plan_km > 0 else 0,
        "–û—Ç–ª": round(km_5, 3),
        "–•–æ—Ä": round(km_4, 3),
        "–£–¥–æ–≤": round(km_3, 3),
        "–ù–µ—É–¥": round(km_2, 3)
    }

# --- –ò–ù–¢–ï–†–§–ï–ô–° ---
st.title("üìä –ï–¥–∏–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –ü–ß-22")
st.markdown("---")

df_struct = load_admin_structure(URL_STRUCT)

if df_struct is not None:
    st.sidebar.success("‚úÖ –°–ø—Ä–∞–≤–æ—á–Ω–∏–∫ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∑–∞–≥—Ä—É–∂–µ–Ω")
    uploaded_file = st.sidebar.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª '–û—Ü–µ–Ω–∫–∞ –ö–ú'", type=["xlsx"])
    
    if uploaded_file:
        try:
            # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è
            df_raw = pd.read_excel(uploaded_file, sheet_name="–û—Ü–µ–Ω–∫–∞ –ö–ú")
            df_raw.columns = [col.strip().upper() for col in df_raw.columns]
            
            # –§–∏–ª—å—Ç—Ä –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π (–∫–∞–∫ –≤ —Å—Ç–∞—Ä–æ–π –ø—Ä–æ–≥—Ä–∞–º–º–µ)
            main_codes = ['24701', '24602', '24603']
            df_eval = df_raw[df_raw["–ö–û–î–ù–ê–ü–†"].astype(str).isin(main_codes)].copy()

            # 2. –ü–ª–∞–Ω –∏–∑ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞
            pd_plan_map = df_struct.groupby('–ü–î')['–ü–õ–ê–ù_–î–õ–ò–ù–ê'].sum().to_dict()

            # 3. –†–∞—Å—á–µ—Ç –õ–∏–Ω–µ–π–Ω—ã—Ö (–ü–î)
            final_stats = []
            for pd_id, group in df_eval.groupby("–ü–î"):
                p_km = pd_plan_map.get(pd_id, 0)
                final_stats.append(calculate_metrics(f"–ü–î-{pd_id}", group, "–õ–∏–Ω–µ–π–Ω—ã–π", p_km))

            # 4. –†–∞—Å—á–µ—Ç –ì—Ä—É–ø–ø–æ–≤—ã—Ö (–ü–ß–ó / –ü–ß–£)
            groups_config = {
                "–ü–ß–ó –Æ–≥": [1, 2, 3, 4, 5, 12],
                "–ü–ß–ó –ó–∞–ø–∞–¥": [6, 7, 8, 9, 10, 11, 13, 14, 15],
                "–ü–ß–£-2": [4, 5, 12]
            }
            
            for g_name, pds in groups_config.items():
                g_data = df_eval[df_eval["–ü–î"].isin(pds)]
                g_plan = sum([pd_plan_map.get(p, 0) for p in pds])
                final_stats.append(calculate_metrics(g_name, g_data, "–ì—Ä—É–ø–ø–æ–≤–æ–π", g_plan))

            results_df = pd.DataFrame(final_stats)

            # --- –ú–ï–¢–†–ò–ö–ò ---
            total_fact = df_eval["–ü–†–û–í–ï–†–ï–ù–û"].sum()
            total_plan = sum(pd_plan_map.values())
            
            c1, c2, c3 = st.columns(3)
            with c1:
                avg_n = results_df[results_df["–£—Ä–æ–≤–µ–Ω—å"]=="–ì—Ä—É–ø–ø–æ–≤–æ–π"]["N—É—á"].mean()
                st.metric("–°—Ä–µ–¥–Ω–∏–π N—É—á –ø–æ –ü–ß", round(avg_n, 2))
            with c2:
                st.metric("–ü–æ–ª–Ω–æ—Ç–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏", f"{round(total_fact/total_plan*100, 1)}%")
            with c3:
                st.metric("–ù–µ—É–¥ (–∫–º)", round(df_eval[df_eval['–û–¶–ï–ù–ö–ê']==2]['–ü–†–û–í–ï–†–ï–ù–û'].sum(), 2))

            # --- –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø ---
            tab1, tab2, tab3 = st.tabs(["üìã –ò—Ç–æ–≥–∏", "üìà –ì—Ä–∞—Ñ–∏–∫–∏", "üîç –¶–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å –ø—É—Ç–∏"])

            with tab1:
                st.dataframe(
                    results_df.style.background_gradient(subset=['N—É—á'], cmap='RdYlGn', vmin=3, vmax=5)
                    .background_gradient(subset=['–ü–æ–ª–Ω–æ—Ç–∞ %'], cmap='YlOrRd', vmin=80, vmax=100),
                    use_container_width=True
                )

            with tab2:
                fig = px.bar(results_df[results_df["–£—Ä–æ–≤–µ–Ω—å"]=="–õ–∏–Ω–µ–π–Ω—ã–π"], 
                             x="–ì—Ä—É–ø–ø–∞", y="N—É—á", color="–ü–æ–ª–Ω–æ—Ç–∞ %", 
                             title="–ö–∞—á–µ—Å—Ç–≤–æ –ø–æ –ü–î (–¶–≤–µ—Ç = –ü–æ–ª–Ω–æ—Ç–∞)", text_auto=True)
                st.plotly_chart(fig, use_container_width=True)

            with tab3:
                st.subheader("–°–≤–µ—Ä–∫–∞ –ø–æ –ü—É—Ç–∏ –∏ –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—é")
                path_fact = df_eval.groupby(['–ö–û–î–ù–ê–ü–†', '–ü–£–¢–¨', '–ü–î'])['–ü–†–û–í–ï–†–ï–ù–û'].sum().reset_index()
                path_plan = df_struct.groupby(['–ù–ê–ü–†–ê–í–õ–ï–ù–ò–ï', '–ü–£–¢–¨', '–ü–î'])['–ü–õ–ê–ù_–î–õ–ò–ù–ê'].sum().reset_index()
                
                detail_check = path_plan.merge(
                    path_fact, left_on=['–ù–ê–ü–†–ê–í–õ–ï–ù–ò–ï','–ü–£–¢–¨','–ü–î'], 
                    right_on=['–ö–û–î–ù–ê–ü–†','–ü–£–¢–¨','–ü–î'], how='left'
                ).fillna(0)
                detail_check['–î–ï–§–ò–¶–ò–¢ (–ö–ú)'] = (detail_check['–ü–õ–ê–ù_–î–õ–ò–ù–ê'] - detail_check['–ü–†–û–í–ï–†–ï–ù–û']).round(3)
                st.dataframe(detail_check.drop(columns=['–ö–û–î–ù–ê–ü–†']), use_container_width=True)

            # --- –≠–ö–°–ü–û–†–¢ EXCEL ---
            st.sidebar.markdown("---")
            st.sidebar.header("üì• –°–∫–∞—á–∞—Ç—å –æ—Ç—á–µ—Ç")
            
            buffer = io.BytesIO()
            with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                results_df.to_excel(writer, sheet_name='–ò–¢–û–ì–ò_–û–ë–©–ò–ï', index=False)
                detail_check.to_excel(writer, sheet_name='–ü–û–õ–ù–û–¢–ê_–î–ï–¢–ê–õ–¨–ù–û', index=False)
                # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
                for score, name in {5: "–û—Ç–ª–∏—á–Ω—ã–µ", 4: "–•–æ—Ä–æ—à–∏–µ", 3: "–£–¥–æ–≤–ª", 2: "–ù–µ—É–¥"}.items():
                    subset = df_eval[df_eval["–û–¶–ï–ù–ö–ê"] == score]
                    subset.to_excel(writer, sheet_name=name, index=False)

            st.sidebar.download_button(
                label="–°–∫–∞—á–∞—Ç—å Excel (.xlsx)",
                data=buffer.getvalue(),
                file_name="Analiz_PCH22_Full.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )

        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –≤ –∫–æ–¥–µ: {e}")
            st.exception(e)
else:
    st.info("–û–∂–∏–¥–∞–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞...")
